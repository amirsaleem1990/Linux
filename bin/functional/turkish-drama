#!/home/amir/github/virtual_envs/turkish_drama_venv/bin/python3
import requests
from bs4 import BeautifulSoup
import pickle
import os
import youtube_dl
from get_soup_object_using_selenium import extract_urls_from_soup_object

class turkis_dramas:
    
    def __init__(self):
        self.kurlus_url = "https://ardirilisertugrul.net/Kurulus-Osman/home.php"
        self.alp_url = "https://ardirilisertugrul.net/series/AlpArslan-Buyuk-Selcuklu-series"
        self.barbarosa_url = "https://ardirilisertugrul.net/Barbaros/home.php"
        self.destan_url = "https://ardirilisertugrul.net/series/Destan-series"
        self.jalaluddin = "https://ardirilisertugrul.net/series/Mendirman-Jaloliddin-series"

        self.file_name = "/home/amir/github/Amir-personal/turkish_daramas_last_viewed.pkl"

    def load_last_viwed_episode_numbers(self):
        if os.path.exists(self.file_name):
            self.last_viwed_versions = pickle.load(open(self.file_name, 'rb'))
        else:
            self.build_latest_episode_number_if_not_exists()
            
    def get_latest_episode_number(self, url):
        s = BeautifulSoup(requests.get(url).text, "lxml")
        latest_episode = int([i.text.split()[-1] for i in s.find("div", {"class" : "row", "style" : "direction:ltr;"}).select("button")][0])
        return latest_episode
    
    def build_latest_episode_number_if_not_exists(self):
        print(f"\nFile '{self.file_name}' not found, Let's create it manually...")
        
        self.last_viwed_versions = {}

        self.last_viwed_versions["KURULUS"] = int(input("What is last episode you watched for 'KURULUS'?"))
        self.last_viwed_versions["ALP"] = int(input("What is last episode you watched for 'ALP'?"))
        self.last_viwed_versions["BARBAROSA"] = int(input("What is last episode you watched for 'BARBAROSA'?"))
        self.last_viwed_versions["DESTAN"] = int(input("What is last episode you watched for 'DESTAN'?"))
        self.last_viwed_versions["JALALUDDIN"] = int(input("What is last episode you watched for 'JALALUDDIN'?"))

        pickle.dump(self.last_viwed_versions, open(self.file_name, 'wb'))

    def get_last_viewed_episode(self, drama_name):
        return self.last_viwed_versions[drama_name]

    def print_new_video_url(self, drama_name, latest_episode_number):
        if drama_name == "KURULUS":
            print("https://ardirilisertugrul.net/Kurulus-Osman/Episode/Kurulus-Osman-Season-4-Episode-" + str(latest_episode_number))
        elif drama_name == "ALP":
            print("https://ardirilisertugrul.net/episode/AlpArslan-Buyuk-Selcuklu-episode-" + str(latest_episode_number))
        elif drama_name == "BARBAROSA":
            print("https://ardirilisertugrul.net/Barbaros/Barbaroslar-Episode-" + str(latest_episode_number))
        elif drama_name == "DESTAN":
            print("https://ardirilisertugrul.net/episode/Destan-episode-" + str(latest_episode_number))
        elif drama_name == "JALALUDDIN":
            print("https://ardirilisertugrul.net/episode/Mendirman-Jaloliddin-episode-" + str(latest_episode_number))

    def dump(self, drama_name, latest_episode_number): 
        self.last_viwed_versions[drama_name] = latest_episode_number
        pickle.dump(self.last_viwed_versions, open(self.file_name, 'wb'))

    def historicales(self):

        def vid_duration(url):
            x = (
                youtube_dl
                .YoutubeDL({'outtmpl': '%(id)s.%(ext)s', 'noplaylist' : True})
                .extract_info(url, download=False) # We just want to extract the info
            )
            video_seconds = x['duration'] # seconds
            video_hours = video_seconds / 60 / 60
            if video_hours > 1:
                print("New videw")
                print(url)
            else:
                print("Trailer")

        kurlus_url = "https://historicales.com/kurulus-osman-episode-"
        alp_url = "https://historicales.com/alparslan-buyuk-selcuklu-episode-"
        barbarosa_url = "https://historicales.com/barbaroslar-episode-"
        destan_url = "https://historicales.com/destan-episode-"
        jalaluddin = "https://historicales.com/bozkir-arslani-celaleddin-episode-"

        for _url, drama_name in zip(
            [barbarosa_url,destan_url,jalaluddin,alp_url,kurlus_url], 
            ["BARBAROSA", "DESTAN", "JALALUDDIN", "ALP", "KURULUS"]
        ):
            print("\n>>>>", drama_name, end="\t")
            url = _url + str(self.last_viwed_versions[drama_name]+1)
            s = BeautifulSoup(requests.get(url).text, "lxml")
            if 'Error 404' in str(s):
                print("No new video or trailer")
                continue

            downloadable_urls = None
            try:
                downloadable_urls = list(set([i.replace("?autoplay=1", "") for i in extract_urls_from_soup_object(s) if i.startswith("//ok.ru")]))
            except:
                pass
            if downloadable_urls is not None:
                downloadable_urls = ["https:" + i for i in downloadable_urls]
            for i in downloadable_urls:
                vid_duration(i)

    def main(self):
        new_dramas = []
        self.load_last_viwed_episode_numbers()
        for url, drama_name in zip([self.kurlus_url, self.alp_url, self.barbarosa_url, self.destan_url, self.jalaluddin], ["KURULUS", "ALP", "BARBAROSA", "DESTAN", "JALALUDDIN"]):
            latest_episode_number = self.get_latest_episode_number(url)
            if latest_episode_number > self.get_last_viewed_episode(drama_name):
                new_dramas.append(drama_name)
                self.dump(drama_name, latest_episode_number)
                self.print_new_video_url(drama_name, latest_episode_number)
        if new_dramas:
            print("\n\nNew dramas:")
            print("\n".join(new_dramas))
        else:
            print("\nNO NEW DRAMA")

        print("\n\n\n>>>>>>>>>>>>>>>> historicales <<<<<<<<<<<<<<<<<<")
        self.historicales()
        
turkis_dramas().main()